%!TEX root = ..\Main.tex
\chapter{Answer to research question}
In this chapter the answers for both papers research questions will be presented.
\section{Paper 1}
In this paper it was explored that it is possible to gather physiological data through sensors, and further use this data to predict subjective SAM ratings with individual sensors as well as using fusion techniques. 
Participants were subjected to stimuli in the form of IAPS pictures, presented in a self developed application. 
They also reported subjective SAM values after each stimulus. 
Synced physiological data was collected in another application, and the sensors used were GSR, EEG, Pulse Sensors as well as a Kinect.
A SVM was selected as the classification technique and fusion techniques were stacking and voting.

In paper one there was the following hypotheses:
\begin{itemize}
    \item \textbf{H1:} Physiological measurements from consumer-grade sensors using a classification technique can achieve significantly higher accuracy than naive guessing when predicting subjective SAM ratings.
    \item \textbf{H2:} Statistically, fusion of consumer-grade sensors has a significantly
higher prediction rate than each sensor individually.
\end{itemize}

Results of the classification showed that naively guessing a class was significantly worse in all cases beside voting on the valance3 group. 
This confirms the hypothesis H1. The result can be seen in Table 7 in paper 1.

The second hypothesis propose that using machine learning fusion techniques for multiple sensors are better than using a single sensor. 
Results show that the technique ``voting'' is not substantially better than single sensors and other methods, however the technique ``stacking'' performs significantly better than most methods. 

This confirms the second hypothesis. The results can be seen in Table 8 and 9 in the paper 1.

\section{Paper 2}
In paper 2 the idea that it was possible to find usability problems from a users affective state was explored. 
A ML technique called novelty detection was used, while making use of a one-class SVM to predict outliers.
A self developed simulation of an email client was used as the framework for the test, in which the test participants would experience seeded usability problems.
The collected data included GSR, EEG, heart rate and facial data from a kinect. 
Sensor fusion was done in the form of voting.

The paper had the following research questions:

\textit{Is it possible to detect usability problems from physiological data gathered during testing?}

\textit{Could a combination of physiological data gathered from multiple sensors possibly increase the reliability of such detections?}

The results showed that it is possible to detect usability to some degree. 
Some of the best results included the GSR which could detect 14.5\% of the usability problem related events, while only having an additional 7.2\% noise. 
The Kinect had similar results with an event hit rate of 21.7\% and a noise level of 10\%. 
True for all results is that as the thresholds for when an outlier is considered an outlier is decreased, then it is possible to hit more events, but at the cost of considerable additional noise.

Voting was done both conservatively and aggressively.
The conservative approach arguebly had the best results when two sensors or more had to agree on an outlier, with 23.2\% event hit rate, with 12.7\% noise.
The aggressive approach had considerable more noise, but had the best results of all sensors and fusion at 3 votes required.
It had 72.1\% event hit rate, but with 58\% noise.

More interestingly was the differences when looking at the best five test participants versus the worst test participants. 
They both had similar amounts of training data to predict against, but the best five used significantly more time on the test in total.
The best five used 19 minutes, whereas the worst used 13 minutes 48 seconds. 
This may allow for the test participants to relax more after each frustrating event, which in terms yield less noise. 
