%!TEX root = ..\Main.tex

\section{Method}
In order to reject or confirm our hypotheses, a test was created.
Test participants were exposed of a program with seeded usability problems and physiological data was collected using different sensors while the system was in use. 
The collected data was subsequently used to train a classifier\todo{SVM?} which can be used to classify usability problems from normal use.\todo{Maybe change to something not classifier specific but more outlier specific.}

\subsection{Test program}
A software application was developed specifically for this test. 
Jussi P.P. Jokinen\cite{workplace_up_study} had test participants complete tasks in four every-day work applications (text editing, image processing, browser usage and presentation editing). 
Lazar et al.\cite{frustration_with_computers} found that text-processing and email related tasks had the highest amount of frustrating experiences.
Since our goal is to have a familiar test setting with seeded problems, we have elected for an email client as the application of choice.

The application was built upon a self developed framework which facilitated seeding usability problems and creating a set of tasks for the user to complete. 
An attempt was made to keep the application simple and low on functionality, to decrease the risk of unintentionally introducing usability problems, but still having the basic functionalities of a normal email application.  
The UPs associated with a specific task were only active when the task was active. 
For instance a particular task involved attaching an image to an email. 
While the task is active, the attachment process will fail three times and be successful on the fourth. 
Had any other task been active the attachment process would not contain the seeded usability problem.
The program had a total of 11 tasks of which 7 contained a seeded usability problem. 
All tasks were randomized for each test participant beside the first two which contained no seeded problems, and were used for baseline training data for outlier detection. 
Each task and their associated usability problem can be seen in the below. 
Task 3 and 7 can be considered full stoppers, and are incompletable. 
Tasks 1, 2, 4, 5 and 6 can be completed given persistence or explorative user behaviour, e.g. task 6 will in fact remove the contact, but to see it has done so requires the user to close the window and reopen it to validate it.
\subsection*{1. Add Attachment}  
Description: The user has to add an attachment to a mail.\\
Seeded problem: The program will ``hang'' for 2 seconds three times, before the attachment can be completed.
\subsection*{2. Add Contact}
Description: The user has to add a new contact to the contacts catalogue.\\
Seeded problem: The ``Add Contact'' button will not work for the first three clicks.
\subsection*{3. Send Draft}
Description: The user has to find a draft, either by created a mail and drafting it or selecting a pre-created draft, and send it.\\
Seeded Problem: An exception will show when they try to open the draft, making it impossible to send.
\subsection*{4. Create a draft}
Description: The user has to create a draft with the body: ``Rød grød med fløde''.\\
Seeded problem: The keyboard language has been changed to American, making it impossible to write the Danish character ``Ø''.
\subsection*{5. Write a mail}
Description: The user has to create a mail with the body: ``Hi, my name is x and I am participating in a usability test''.\\
Seeded problem: At random intervals the caret will move while writing the mail.
\subsection*{6. Remove Contact}
Description: The user has to remove a specific contact from the contacts catalogue.\\
Seeded Problem: When clicking ``Delete'' the entire window will change to a black box.
\subsection*{7. Write mail 2}
Description: The user has to write a mail with the body text ``Hello, I am having a birthday party 10 days from now, and this is your invitation!''.\\
Seeded problem: The window for writing a mail is unavailable, and the title changes to ``Not responding..''.
\subsection*{8. Send a mail}
Description: The user has to send a mail with any text, to two contacts.\\
Seeded problem: none.
\subsection*{9. Save a draft}
Description: The user has to create a mail, and draft it.\\
Seeded problem: none.
\subsection*{10. Reply to mail}
Description: The user has to reply to a mail.\\
Seeded problem: none.
\subsection*{11. Write and delete mail}
Description: The user has to write a mail containing any text, draft it and then delete it.\\
Seeded problem: none.

\subsection{Hardware}
The hardware used for the experiment is an Emotiv Epoc~\cite{emotiv_epoc_website} for Electroencephalograph (EEG) to recording brain activity, a Mindplace Thoughtstream~\cite{thoughtstream} for Galvanic Skin Response (GSR), an Arduino with a pulse-sensor~\cite{pulsesensor} with modified software~\cite{pulsesensorgit} to measure heart rate (HR) and a Kinect V2\cite{kinect_specs3} for tracking facial changes.
The pulse-sensor software was modified to send beats per minute (BPM), inter-beat interval (IBI) and raw signal every 20 ms.
All devices are low-cost consumer grade hardware.

\subsection{Participants}
A total of 29 people participated in the test (16 male, age XX-XX SD X, 13 female age YY-YY SD Y).
The participants were students recruited from multiple faculties at Aalborg University.

\subsection{Setup}
The tests were conducted from the 13th of April, 2016, to the 30th of April 2016 and from 8:00 to 16:00 every day. 
The participants were asked to fill out a consent form prior participation. 
The participants were instructed in how to use the test program which included how to see the tasks, and how to indicate whether or not they could complete the given task. 
Before starting the test all hardware was attached to the participant and verified in terms of connectivity. 
The EEG was connected to the head according to the 10-20 system\cite{eeg_tech_10_20}, the GSR and pulse sensor was attached to their non-dominant hand. 

\subsection{Test procedure}
The test starts with an application the mail client simulation.
In the bottom right corner of the application a ``task'' window is located, which contains information regarding the test participants current task. 
A red and green button indicated that you have ``completed'' or ``not completed'' a task.  
Each task had an indefinite time threshold, but the participant could choose to continue to the next task at any given moment by pressing either a green or a red button on the keyboard. 
The participants were not allowed to talk to the test conductor during the test, unless it was absolutely necessary. 
In case any communication had to take place, it would be done through a microphone and speakers.


\subsection{What indicates a user experience problem?}
Usability tests has been done for a long time, and as mentioned they usually focus on performance metrics. 
The practice of this has been covered in numerous articles and books, and the concept ``usability problem'' is well defined.
There is, however, a fundamental difference between a usability problem, and a user-experience problem(UEP). 
Where the usability problem is focused on task completion and effort required, the UEP is focused on the users affective state. 
While this can be observed/collected through third party measures (think aloud, expert evaluations etc), it has always been a low resolution, subjective measure. 
There is no conclusive literature regarding how a UEP unfolds it self on a physiological level, and no models that accurately depict the evolution of a user-experience problem. 
While some papers has dealt with single sensors such as \cite{mind_the_gap} \cite{LH-paper}, the basic extraction of interesting physiological responses are based upon expert analysis of the data.
While these interesting parts of a physiological response may to some extent be verified against cued-recall of the same points in time, it is inherently biased and suffers from the concept of the evaluator effect. 
There is simply no guarantee that all anomalies regarding usability problems have been extracted from the data.
This lack of a formal description of how user-experience problems unfolds it self on a physiological level over time, makes any definition of how to detect these anomalies regarding a UEP an educated guess from the researchers.
Due to limitations and the scope of this study, we will not attempt to formalize the problems outlined above, we do however outline the definitions used in this paper to describe and detect UEPs.

\subsection{User experience problem definition}
The definition in this paper is part based on literature and data analysis.
\todo{Vis nogle grafer for hvordan mange peaks ser ud efter et event, snak om latency og duration etc}
