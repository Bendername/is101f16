%!TEX root = ..\Main.tex
	%Intro <- Hvad er det vi vil?
				%Vi skal ikke mudre billedet til. (ren focus på hvad artiklen vil)
\section{Introduction}
%http://delivery.acm.org.zorac.aub.aau.dk/10.1145/2500000/2491883/p258-liapis.pdf?ip=130.225.53.20&id=2491883&acc=ACTIVE%20SERVICE&key=36332CD97FA87885%2E1DDFD8390336D738%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=764220047&CFTOKEN=51730471&__acm__=1459164823_6fcb563aae9287be26350addc8efbe52
%artikel vi kan bruge som støtte.

Usability testing has long been an important aspect of software development and according to Rubin et al.~\cite{rubin2008handbook} usability testing is user centered tests that focuses on three main groups.
Informing Design, which concerns the usefulness and learning rate of the program.
Elimination of design problems and frustration, which not only focuses on removing design problems and bugs, but is also about establishing a good relation to the customer.
The last group is improving profitability, which is centered around reducing maintenance and increasing sales.
However the second group, elimination of design problems and frustration, is often measured with methods involving third part observers.
These observers has to, as objectively as possible, note if a test person is encountering a usability problem.
However, such observations are often still very subjective given the evaluator effect\cite{eval_effect}, which states that the results from the evaluations are different from individual to individual.
Strategies such as \textit{think aloud}~\cite{use_of_TA_and_IDA} can help observers better gauge a user's
thoughts, and to some extent affective state, while experiencing UP's. However it does
not formalise capturing of the affective state in particular and is inherently a third-party
subjective evaluation. 

There are three predominant methods formalised for capturing a user's affective state: affective self-report, physiological reactivity and
observable behaviour~\cite{BRADLEY199449}. Strategies such as \textit{think
aloud} fall within the \textit{observable behaviour} category, while
\textit{self-report} covers methods such as \textit{Self-Assessment Manikin}
~\cite{BRADLEY199449}, both of which suffers from subjectivity-bias. 
Observable behaviors inherently so because third-party evaluators are making a subjective opinion based off their own estimations and analysis' which can vary due to the evaluator effect, and SAM because of effects like the peak-end memory bias \cite{cockburn_peakend}.
Physiological measuring has shown at several occasions\todo{cite} that it can, to some degree, be used to predict a persons affective state, and thus has interesting propositions to offer to the traditional evaluation methods.

An example of such study was made by Bruun et al.~\cite{LH-paper}, who made a usability case-study based on a website.
A number of UP's were found in a prior empirical study, from which they created three tasks for the participants to complete.
They recorded physiological data using \textit{galvanic skin response} (GSR) which measures sweat \cite{gsr_calibration}, and an eye-tracker detecting the gaze of the participant.
They formalized a method and a formula for associating the physiological data with the discrete negative affect state \textit{frustration}.
As mentioned in multiple studies, e.g. ~\cite{LH-paper}, ~\cite{frustration_with_computers}, frustration is well-studied
and manifests whenever expectations or rewards are not met in a timely manner or conflict when a goal is compromised in one way or another. These traits match the signature of a UP.
Bruun et al. also had a cued-recall debrief session where the participants reviewed video clips found from GSR peaks, and filled out SAM scales relating to the clip. 
They found a correlation between peaks in GSR and SAM-ratings, but was unable to confirm a relationship between the
\textit{severity} of a UP and the level of frustration experienced.
While they found a correlation, the entire study still relies on the preliminary assumption that the UPs found by
third-party evaluations on the website in question are correct. 
As mentioned such evaluations suffer from various problems, and are generally only expected to find a subset of the UPs present in a system. 
This raises the question if the sensors where detection ``actual'' problems and how they would perform in a more controlled environment.

Our focus in this study will be to use multiple physiological sensors to detect usability problem. We aim to use
consumer graded sensors, to make our setup more accessible should other researchers find the interest to reproduce
it. We couple physiological data from various sensors with established Machine Learning techniques as the method for
detecting usability problems.