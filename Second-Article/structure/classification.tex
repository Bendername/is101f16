\section{Classification}
The use case of this article is to help third-party evaluators find usability problems in a usability test.
In a usability test the usability problems will occur an as an unknown class for the classifier, meaning that the classifier has model for the class that would be a usability problem. 
We therefore have to limit our choice of classifiers to the ones who can predict anomalies by only learning on the ´´´normal'' class.
Additionally the usability test is expected to have many normalities and only a small portion of anomalies.
This problem fits the scope of novelty detection\cite{noveltyDetection}.

There are many different method when working with novelty detection\cite{noveltyDetection}, and choosing the right one is not easy.
The different methods are divided into five subgroups probabilistic, distance based, domain based, reconstruction based, and information theoretic.
Manevitz et al.~\cite{oneClassSVM} showed that an One-class SVM achieved on average better results than neural networks, naive Bayes, nearest neighbor and prototype over a series of dataset.
Thus to predict whether or not a usability problem is present a one-class SVM is used.
The goal of the classification will be to explorer the one-class SVM's behaviour when detecting usability, given its parameters.

\subsection{One-class SVM}
The one-class SVM is domain based an algorithm used for novelty detection, meaning it creates a boundary given its training data, and the unknown data is then labelled as a normality or anomaly regarding to its to position relative to the boundary.
Since the one-class SVM is sensitive\cite{oneClassSVM} to its parameter setting a grid search on the hyperparameters $Gamma = \{2^{-14},..,2^2\}$ is performed, together with the Sigmoid and RBF kernel, to find the optimal parameters where the Nu parameter is held at 0.05.
We use LibSVMSharp\cite{libsvmsharp}, a wrapper for LibSVM\cite{libsvm}, which is a library that have implemented a one-class SVM, since LIBSVM it is a widely used library for a SVM implementation.

\subsection{Prediction \& Scoring}
We create a one-class SVM for each of the sensors where each of the SVM's trains on the data from the first two tasks, which is design to contain no usability errors e.g. no anomalies. The model created can then be used to predict on remainder of the data.
A prediction from a one-class SVM is a binary 1 for a normality and -1 for an anomaly for the given a data point.
Which results in a collection of data points labelled with a 1 for normality or -1 for anomaly.

To decide whether an anomaly correctly hits an usability error some assumptions has to be made. Given our grouping of the task into instant error feedback and non instant error feedback, a split has to be made. The usability errors found in the instant error feedback tasks will be assigned to the specific time the error happened. Whereas for the non instant error feedback tasks will span from the first usability error related to that task to the last error related to that task has occurred, as illustrated in Figure x.x.
\todo{Make figure of this}
When an anomaly is found an area of 2.5 seconds to each side it is marked around is, to create a point of interest. The point of interest is created to satisfy the use case of a third-party evaluator having to look through the video, and thus the evaluator should have more than just a millisecond to see the problem.
To evaluate if an event is correctly found by the machine the two types of events will be considered again.
The events which contain instant feedback is classified as a hit the points of interest covers the time of which the event happens.
For the events which does not contain instant feedback, as mentioned before, an area for when the usability errors start to when the errors stops again is marked, if the point of interest hits inside the area the event will be marked as hit, both of these examples is illustrated in Figure x.x. \todo{Make Figure}

Two scoring functions are used to optimize the gamma value in the line search. The first function is defined as: 
\[CovScore = \frac{2 \times EventsHitRate \times 1-FalseCoverRate}{EventsHitRate + FalseCoverRate}\]
Where \textit{EventHitRate}(EHR) describes how many of the existing events has been hit by an anomaly e.g. $EHR = \frac{DifferentEventsHit}{TotalNumberOfEvents}$, and \textit{FalseCoverRate}(FCR) is the rate of which the area outside events that has been covered e.g $FCR = \frac{NonEventAreaCovered}{TotalNonEventArea}$. 
The scoring function is the harmonic mean of EHR and FCR which is a kind of averaging of the two rates.
A low score from this function will the machines which have a low EHR and/or high FCR would make the numerator approach zero, while having a high EHR and low FCR will make the function approach 1 which is the ideal result.
Meaning this function rewards hit as many different events higher than hitting the same multiple times, while also considering the rate of FCR.
The second function is defined as: 
\[HitScore = \frac{2 \times EventsHitRate \times Presicion}{EventsHitRate + Precision}\]
Where \textit{Precision} is the rate of which the anomalies found by the SVM hits an event e.g. $precision = \frac{hits}{hits+misses}$. 
As with the first scoring function the second scoring function is a harmonic mean but with EHR and precision.
Meaning the function rewards spreading of the answers while having a high true positive rate on its guesses.

Since the Nu parameter indirectly dictates how much of the training data that should be inside the boundary an examination of what the Nu parameter impact is on the classification will be done.\todo{Kan ikke lide den her sætning men har skrevet den anywho}
This will be done using a line search, locking all the parameters except the $Nu = \{0.01, 0.02,.., 1\}$. 
